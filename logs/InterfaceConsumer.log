[[1;34mINFO[m] Scanning for projects...
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m-----------------------------< [0;36mkafka:src[0;1m >------------------------------[m
[[1;34mINFO[m] [1mBuilding src 1.0-SNAPSHOT[m
[[1;34mINFO[m] [1m--------------------------------[ jar ]---------------------------------[m
[[1;34mINFO[m] 
[[1;34mINFO[m] [1m--- [0;32mexec-maven-plugin:3.1.0:java[m [1m(default-cli)[m @ [36msrc[0;1m ---[m
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-coffee-sales-consumer-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = coffee-sales-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

[kafka.InterfaceConsumer.main()] WARN org.apache.kafka.clients.consumer.ConsumerConfig - These configurations '[spring.json.trusted.packages]' were supplied but are not used yet.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434424386
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Subscribed to topic(s): coffee_sales
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Resetting the last seen epoch of partition coffee_sales-0 to 0 since the associated topicId changed from null to GBNK__7-ROmqHqdPos_FoQ
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Discovered group coordinator matheus:9092 (id: 2147483647 rack: null)
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] (Re-)joining group
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Request joining group due to: need to re-join with the given member-id: consumer-coffee-sales-consumer-group-1-0539a4e9-8dd4-422a-a902-77a2b9e036e1
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException)
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] (Re-)joining group
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-coffee-sales-consumer-group-1-0539a4e9-8dd4-422a-a902-77a2b9e036e1', protocol='range'}
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Finished assignment for group at generation 1: {consumer-coffee-sales-consumer-group-1-0539a4e9-8dd4-422a-a902-77a2b9e036e1=Assignment(partitions=[coffee_sales-0])}
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-coffee-sales-consumer-group-1-0539a4e9-8dd4-422a-a902-77a2b9e036e1', protocol='range'}
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Notifying assignor about the new Assignment(partitions=[coffee_sales-0])
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Adding newly assigned partitions: coffee_sales-0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Found no committed offset for partition coffee_sales-0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.consumer.internals.SubscriptionState - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Resetting offset for partition coffee_sales-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[matheus:9092 (id: 0 rack: null)], epoch=0}}.
Received message: 4.508731672305022
COUNT: 1
Received message: 4.508731672305022
COUNT: 2
Received message: 4.508731672305022
COUNT: 3
Received message: 4.508731672305022
COUNT: 4
Received message: 4.508731672305022
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434715629
[kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 276 with epoch 0
[kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-1 unregistered
Aumentou o pre√ßo do caf√©
Received message: 4.508731672305022
COUNT: 1
Received message: 6.0942840252162
COUNT: 2
Received message: 6.0942840252162
COUNT: 3
Received message: 6.0942840252162
COUNT: 4
Received message: 6.0942840252162
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-2] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434716449
[kafka-producer-network-thread | producer-2] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-2] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-2] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-2] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-2] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-2] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-2] ProducerId set to 279 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-2 unregistered
Aumentou o pre√ßo do caf√©
Received message: 6.0942840252162
COUNT: 1
Received message: 6.0942840252162
COUNT: 2
Received message: 6.0942840252162
COUNT: 3
Received message: 6.0942840252162
COUNT: 4
Received message: 6.0942840252162
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-3] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434717287
[kafka-producer-network-thread | producer-3] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-3] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-3] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-3] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-3] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-3] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-3] ProducerId set to 280 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-3 unregistered
Aumentou o pre√ßo do caf√©
Received message: 6.0942840252162
COUNT: 1
Received message: 6.0942840252162
COUNT: 2
Received message: 6.0942840252162
COUNT: 3
Received message: 7.40236471636792
COUNT: 4
Received message: 7.40236471636792
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-4
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-4] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434718171
[kafka-producer-network-thread | producer-4] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-4] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-4] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-4] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-4] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-4] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-4] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-4] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-4] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-4] ProducerId set to 283 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-4 unregistered
Aumentou o pre√ßo do caf√©
Received message: 7.40236471636792
COUNT: 1
Received message: 7.40236471636792
COUNT: 2
Received message: 8.560958206600642
COUNT: 3
Received message: 8.560958206600642
COUNT: 4
Received message: 8.560958206600642
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-5
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-5] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434719039
[kafka-producer-network-thread | producer-5] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-5] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-5] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-5] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-5] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-5] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-5] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-5] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-5] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-5] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-5] ProducerId set to 287 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-5 unregistered
Aumentou o pre√ßo do caf√©
Received message: 8.560958206600642
COUNT: 1
Received message: 8.560958206600642
COUNT: 2
Received message: 8.560958206600642
COUNT: 3
Received message: 8.560958206600642
COUNT: 4
Received message: 8.560958206600642
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-6
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-6] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434719972
[kafka-producer-network-thread | producer-6] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-6] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-6] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-6] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-6] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-6] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-6] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-6] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-6] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-6] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-6] ProducerId set to 288 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-6 unregistered
Aumentou o pre√ßo do caf√©
Received message: 8.560958206600642
COUNT: 1
Received message: 8.560958206600642
COUNT: 2
Received message: 8.560958206600642
COUNT: 3
Received message: 9.516797836042636
COUNT: 4
Received message: 9.516797836042636
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-7
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-7] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434720824
[kafka-producer-network-thread | producer-7] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-7] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-7] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-7] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-7] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-7] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-7] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-7] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-7] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-7] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-7] ProducerId set to 291 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-7 unregistered
Aumentou o pre√ßo do caf√©
Received message: 9.516797836042636
COUNT: 1
Received message: 9.516797836042636
COUNT: 2
Received message: 9.516797836042636
COUNT: 3
Received message: 9.516797836042636
COUNT: 4
Received message: 10.381498340505523
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-8
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-8] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434721679
[kafka-producer-network-thread | producer-8] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-8] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-8] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-8] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-8] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-8] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-8] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-8] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-8] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-8] ProducerId set to 295 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-8] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-8 unregistered
Aumentou o pre√ßo do caf√©
Received message: 10.381498340505523
COUNT: 1
Received message: 10.381498340505523
COUNT: 2
Received message: 10.381498340505523
COUNT: 3
Received message: 10.381498340505523
COUNT: 4
Received message: 10.381498340505523
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-9
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-9] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434722564
[kafka-producer-network-thread | producer-9] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-9] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-9] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-9] ProducerId set to 296 with epoch 0
[kafka-producer-network-thread | producer-9] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-9] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-9] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-9] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-9] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-9] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-9] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-9 unregistered
Aumentou o pre√ßo do caf√©
Received message: 10.381498340505523
COUNT: 1
Received message: 10.381498340505523
COUNT: 2
Received message: 10.381498340505523
COUNT: 3
Received message: 10.381498340505523
COUNT: 4
Received message: 10.381498340505523
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-10
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-10] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka-producer-network-thread | producer-10] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-10] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434723464
[kafka-producer-network-thread | producer-10] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-10] ProducerId set to 297 with epoch 0
[kafka-producer-network-thread | producer-10] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-10] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-10] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-10] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-10] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-10] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-10] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-10 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.094876256687405
COUNT: 1
Received message: 11.094876256687405
COUNT: 2
Received message: 11.094876256687405
COUNT: 3
Received message: 11.094876256687405
COUNT: 4
Received message: 11.094876256687405
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-11
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-11] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434724455
[kafka-producer-network-thread | producer-11] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-11] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-11] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-11] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-11] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-11] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-11] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-11] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-11] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-11] ProducerId set to 300 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-11] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-11 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.094876256687405
COUNT: 1
Received message: 11.094876256687405
COUNT: 2
Received message: 11.164619960653528
COUNT: 3
Received message: 11.164619960653528
COUNT: 4
Received message: 11.164619960653528
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-12
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-12] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434725296
[kafka-producer-network-thread | producer-12] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-12] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-12] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-12] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-12] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-12] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-12] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-12] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-12] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-12] ProducerId set to 304 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-12] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-12 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.164619960653528
COUNT: 1
Received message: 11.164619960653528
COUNT: 2
Received message: 11.164619960653528
COUNT: 3
Received message: 11.813628353985635
COUNT: 4
Received message: 11.773461475542623
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-13
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-13] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683434959150
[kafka-producer-network-thread | producer-13] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-13] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-13] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-13] ProducerId set to 532 with epoch 0
[kafka-producer-network-thread | producer-13] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-13] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-13] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-13] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-13] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-13] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-13] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-13 unregistered
Aumentou o pre√ßo do caf√©
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-coffee-sales-consumer-group-1, groupId=coffee-sales-consumer-group] Node -1 disconnected.
Received message: 12.391149800752281
COUNT: 1
Received message: 12.391149800752281
COUNT: 2
Received message: 12.764701537360228
COUNT: 3
Received message: 12.764701537360228
COUNT: 4
Received message: 12.764701537360228
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-14
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-14] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka-producer-network-thread | producer-14] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-14] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435128287
[kafka-producer-network-thread | producer-14] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-14] ProducerId set to 698 with epoch 0
[kafka-producer-network-thread | producer-14] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-14] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-14] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-14] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-14] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-14] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-14] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-14 unregistered
Aumentou o pre√ßo do caf√©
Received message: 12.764701537360228
COUNT: 1
Received message: 13.497132453688295
COUNT: 2
Received message: 12.260564073960936
COUNT: 3
Received message: 12.260564073960936
COUNT: 4
Received message: 12.256249719485522
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-15
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-15] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435202975
[kafka-producer-network-thread | producer-15] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-15] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-15] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-15] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-15] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-15] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-15] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-15] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-15] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-15] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-15] ProducerId set to 772 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-15 unregistered
Aumentou o pre√ßo do caf√©
Received message: 12.256249719485522
COUNT: 1
Received message: 12.256249719485522
COUNT: 2
Received message: 12.256249719485522
COUNT: 3
Received message: 12.256249719485522
COUNT: 4
Received message: 11.808811169677803
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-16
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-16] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435203966
[kafka-producer-network-thread | producer-16] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-16] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-16] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-16] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-16] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-16] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-16] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-16] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-16] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-16] ProducerId set to 776 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-16] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-16 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.808811169677803
COUNT: 1
Received message: 11.808811169677803
COUNT: 2
Received message: 11.808811169677803
COUNT: 3
Received message: 11.808811169677803
COUNT: 4
Received message: 11.808811169677803
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-17
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-17] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435204798
[kafka-producer-network-thread | producer-17] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-17] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-17] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-17] ProducerId set to 777 with epoch 0
[kafka-producer-network-thread | producer-17] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-17] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-17] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-17] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-17] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-17] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-17] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-17 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.808811169677803
COUNT: 1
Received message: 11.808811169677803
COUNT: 2
Received message: 11.808811169677803
COUNT: 3
Received message: 11.808811169677803
COUNT: 4
Received message: 11.808811169677803
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-18
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-18] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435205654
[kafka-producer-network-thread | producer-18] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-18] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-18] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-18] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-18] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-18] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-18] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-18] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-18] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-18] ProducerId set to 778 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-18] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-18 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.473232257322014
COUNT: 1
Received message: 11.473232257322014
COUNT: 2
Received message: 11.473232257322014
COUNT: 3
Received message: 11.473232257322014
COUNT: 4
Received message: 11.473232257322014
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-19
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-19] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435206527
[kafka-producer-network-thread | producer-19] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-19] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-19] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-19] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-19] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-19] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-19] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-19] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-19] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-19] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-19] ProducerId set to 781 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-19 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.473232257322014
COUNT: 1
Received message: 11.481601509635414
COUNT: 2
Received message: 11.481601509635414
COUNT: 3
Received message: 11.481601509635414
COUNT: 4
Received message: 11.481601509635414
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-20
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-20] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435207396
[kafka-producer-network-thread | producer-20] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-20] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-20] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-20] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-20] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-20] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-20] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-20] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-20] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-20] ProducerId set to 785 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-20] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-20 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.481601509635414
COUNT: 1
Received message: 11.481601509635414
COUNT: 2
Received message: 11.481601509635414
COUNT: 3
Received message: 11.481601509635414
COUNT: 4
Received message: 11.481601509635414
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-21
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-21] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435208340
[kafka-producer-network-thread | producer-21] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-21] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-21] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-21] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-21] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-21] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-21] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-21] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-21] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-21] ProducerId set to 786 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-21] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-21 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.481601509635414
COUNT: 1
Received message: 11.481601509635414
COUNT: 2
Received message: 11.481601509635414
COUNT: 3
Received message: 11.229917325368575
COUNT: 4
Received message: 11.229917325368575
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-22
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-22] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435209315
[kafka-producer-network-thread | producer-22] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-22] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-22] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-22] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-22] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-22] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-22] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-22] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-22] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-22] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-22] ProducerId set to 789 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-22 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.229917325368575
COUNT: 1
Received message: 11.229917325368575
COUNT: 2
Received message: 11.229917325368575
COUNT: 3
Received message: 11.229917325368575
COUNT: 4
Received message: 11.210448638076443
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-23
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-23] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435210149
[kafka-producer-network-thread | producer-23] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-23] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-23] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-23] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-23] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-23] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-23] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-23] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-23] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-23] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-23] ProducerId set to 793 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-23 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.210448638076443
COUNT: 1
Received message: 11.210448638076443
COUNT: 2
Received message: 11.210448638076443
COUNT: 3
Received message: 11.210448638076443
COUNT: 4
Received message: 11.210448638076443
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-24
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-24] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435211032
[kafka-producer-network-thread | producer-24] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-24] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-24] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-24] ProducerId set to 794 with epoch 0
[kafka-producer-network-thread | producer-24] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-24] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-24] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-24] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-24] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-24] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-24] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-24 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.210448638076443
COUNT: 1
Received message: 11.210448638076443
COUNT: 2
Received message: 11.210448638076443
COUNT: 3
Received message: 11.210448638076443
COUNT: 4
Received message: 11.210448638076443
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-25
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-25] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435212184
[kafka-producer-network-thread | producer-25] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-25] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-25] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-25] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-25] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-25] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-25] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-25] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-25] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-25] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-25] ProducerId set to 797 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-25 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.210448638076443
COUNT: 1
Received message: 11.021685499876313
COUNT: 2
Received message: 11.021685499876313
COUNT: 3
Received message: 11.021685499876313
COUNT: 4
Received message: 11.021685499876313
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-26
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-26] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435212990
[kafka-producer-network-thread | producer-26] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-26] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-26] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-26] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-26] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-26] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-26] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-26] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-26] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-26] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-26] ProducerId set to 799 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-26 unregistered
Aumentou o pre√ßo do caf√©
Received message: 11.021685499876313
COUNT: 1
Received message: 11.021685499876313
COUNT: 2
Received message: 11.091966399628786
COUNT: 3
Received message: 11.091966399628786
COUNT: 4
Received message: 11.091966399628786
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-27
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-27] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435213750
[kafka-producer-network-thread | producer-27] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-27] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-27] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-27] ProducerId set to 802 with epoch 0
[kafka-producer-network-thread | producer-27] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-27] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-27] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-27] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-27] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-27] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-27] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-27 unregistered
Aumentou o pre√ßo do caf√©
Received message: 16.554690419087443
COUNT: 1
Received message: 16.554690419087443
COUNT: 2
Received message: 16.56794650160797
COUNT: 3
Received message: 16.56794650160797
COUNT: 4
Received message: 16.56794650160797
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-28
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-28] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka-producer-network-thread | producer-28] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-28] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka-producer-network-thread | producer-28] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-28] ProducerId set to 822 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435231270
[kafka-producer-network-thread | producer-28] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-28] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-28] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-28] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-28] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-28] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-28] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-28 unregistered
Aumentou o pre√ßo do caf√©
Received message: 16.56794650160797
COUNT: 1
Received message: 16.56794650160797
COUNT: 2
Received message: 16.56794650160797
COUNT: 3
Received message: 22.669876410427662
COUNT: 4
Received message: 22.669876410427662
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-29
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-29] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435235350
[kafka-producer-network-thread | producer-29] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-29] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-29] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-29] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-29] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-29] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-29] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-29] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-29] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-29] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-29] ProducerId set to 827 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-29 unregistered
Aumentou o pre√ßo do caf√©
Received message: 22.669876410427662
COUNT: 1
Received message: 29.53454755784982
COUNT: 2
Received message: 29.53454755784982
COUNT: 3
Received message: 29.53454755784982
COUNT: 4
Received message: 19.68969837189988
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-30
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-30] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435236863
[kafka-producer-network-thread | producer-30] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-30] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-30] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-30] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-30] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-30] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-30] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-30] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-30] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-30] ProducerId set to 830 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-30] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-30 unregistered
Aumentou o pre√ßo do caf√©
Received message: 19.68969837189988
COUNT: 1
Received message: 17.517363821564867
COUNT: 2
Received message: 17.517363821564867
COUNT: 3
Received message: 17.517363821564867
COUNT: 4
Received message: 17.517363821564867
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-31
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-31] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435237731
[kafka-producer-network-thread | producer-31] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-31] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-31] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-31] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-31] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-31] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-31] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-31] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-31] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-31] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-31] ProducerId set to 833 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-31 unregistered
Aumentou o pre√ßo do caf√©
Received message: 17.517363821564867
COUNT: 1
Received message: 15.898240604669198
COUNT: 2
Received message: 15.898240604669198
COUNT: 3
Received message: 15.898240604669198
COUNT: 4
Received message: 15.898240604669198
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-32
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-32] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435238654
[kafka-producer-network-thread | producer-32] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-32] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-32] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-32] ProducerId set to 837 with epoch 0
[kafka-producer-network-thread | producer-32] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-32] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-32] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-32] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-32] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-32] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-32] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-32 unregistered
Aumentou o pre√ßo do caf√©
Received message: 15.898240604669198
COUNT: 1
Received message: 15.898240604669198
COUNT: 2
Received message: 15.898240604669198
COUNT: 3
Received message: 15.898240604669198
COUNT: 4
Received message: 15.898240604669198
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-33
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-33] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435239595
[kafka-producer-network-thread | producer-33] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-33] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-33] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-33] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-33] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-33] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-33] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-33] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-33] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-33] ProducerId set to 838 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-33] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-33 unregistered
Aumentou o pre√ßo do caf√©
Received message: 15.898240604669198
COUNT: 1
Received message: 15.898240604669198
COUNT: 2
Received message: 15.898240604669198
COUNT: 3
Received message: 14.683898191997447
COUNT: 4
Received message: 14.683898191997447
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-34
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-34] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435240970
[kafka-producer-network-thread | producer-34] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-34] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-34] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-34] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-34] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-34] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-34] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-34] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-34] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-34] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-34] ProducerId set to 842 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-34 unregistered
Aumentou o pre√ßo do caf√©
Received message: 14.683898191997447
COUNT: 1
Received message: 13.787703962495819
COUNT: 2
Received message: 13.787703962495819
COUNT: 3
Received message: 13.787703962495819
COUNT: 4
Received message: 13.787703962495819
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-35
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-35] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435241879
[kafka-producer-network-thread | producer-35] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-35] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-35] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-35] ProducerId set to 845 with epoch 0
[kafka-producer-network-thread | producer-35] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-35] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-35] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-35] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-35] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-35] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-35] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-35 unregistered
Aumentou o pre√ßo do caf√©
Received message: 13.787703962495819
COUNT: 1
Received message: 13.787703962495819
COUNT: 2
Received message: 12.824268843505378
COUNT: 3
Received message: 12.824268843505378
COUNT: 4
Received message: 12.824268843505378
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-36
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-36] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435273001
[kafka-producer-network-thread | producer-36] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-36] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-36] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-36] ProducerId set to 876 with epoch 0
[kafka-producer-network-thread | producer-36] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-36] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-36] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-36] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-36] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-36] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-36] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-36 unregistered
Aumentou o pre√ßo do caf√©
Received message: 18.575070927098537
COUNT: 1
Received message: 18.575070927098537
COUNT: 2
Received message: 18.365961645601182
COUNT: 3
Received message: 18.39839480974132
COUNT: 4
Received message: 18.290255811694394
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-37
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-37] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435308712
[kafka-producer-network-thread | producer-37] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-37] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-37] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-37] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-37] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-37] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-37] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-37] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-37] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-37] ProducerId set to 912 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-37] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-37 unregistered
Aumentou o pre√ßo do caf√©
Received message: 24.332422941549595
COUNT: 1
Received message: 24.332422941549595
COUNT: 2
Received message: 24.332422941549595
COUNT: 3
Received message: 24.332422941549595
COUNT: 4
Received message: 24.332422941549595
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-38
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-38] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435310792
[kafka-producer-network-thread | producer-38] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-38] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-38] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-38] ProducerId set to 916 with epoch 0
[kafka-producer-network-thread | producer-38] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-38] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-38] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-38] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-38] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-38] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-38] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-38 unregistered
Aumentou o pre√ßo do caf√©
Received message: 24.332422941549595
COUNT: 1
Received message: 24.332422941549595
COUNT: 2
Received message: 31.129860962636698
COUNT: 3
Received message: 31.129860962636698
COUNT: 4
Received message: 31.129860962636698
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-39
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-39] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435311594
[kafka-producer-network-thread | producer-39] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-39] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-39] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-39] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-39] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-39] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-39] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-39] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-39] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-39] ProducerId set to 919 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-39] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-39 unregistered
Aumentou o pre√ßo do caf√©
Received message: 31.129860962636698
COUNT: 1
Received message: 31.129860962636698
COUNT: 2
Received message: 38.8128830977172
COUNT: 3
Received message: 38.8128830977172
COUNT: 4
Received message: 38.8128830977172
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-40
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-40] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435312929
[kafka-producer-network-thread | producer-40] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-40] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-40] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-40] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-40] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-40] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-40] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-40] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-40] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-40] ProducerId set to 923 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-40] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-40 unregistered
Aumentou o pre√ßo do caf√©
Received message: 38.8128830977172
COUNT: 1
Received message: 38.8128830977172
COUNT: 2
Received message: 38.8128830977172
COUNT: 3
Received message: 38.8128830977172
COUNT: 4
Received message: 38.8128830977172
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-41
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-41] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435313735
[kafka-producer-network-thread | producer-41] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-41] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-41] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-41] ProducerId set to 924 with epoch 0
[kafka-producer-network-thread | producer-41] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-41] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-41] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-41] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-41] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-41] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-41] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-41 unregistered
Aumentou o pre√ßo do caf√©
Received message: 38.8128830977172
COUNT: 1
Received message: 47.32147287867794
COUNT: 2
Received message: 47.32147287867794
COUNT: 3
Received message: 47.32147287867794
COUNT: 4
Received message: 47.32147287867794
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-42
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-42] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435319926
[kafka-producer-network-thread | producer-42] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-42] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-42] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-42] ProducerId set to 931 with epoch 0
[kafka-producer-network-thread | producer-42] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-42] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-42] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-42] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-42] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-42] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-42] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-42 unregistered
Aumentou o pre√ßo do caf√©
Received message: 47.32147287867794
COUNT: 1
Received message: 56.78685446393622
COUNT: 2
Received message: 56.78685446393622
COUNT: 3
Received message: 56.78685446393622
COUNT: 4
Received message: 56.78685446393622
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-43
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-43] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435321281
[kafka-producer-network-thread | producer-43] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-43] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-43] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-43] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-43] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-43] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-43] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-43] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-43] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-43] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-43] ProducerId set to 935 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-43 unregistered
Aumentou o pre√ßo do caf√©
Received message: 56.78685446393622
COUNT: 1
Received message: 56.78685446393622
COUNT: 2
Received message: 67.55467828924527
COUNT: 3
Received message: 67.55467828924527
COUNT: 4
Received message: 67.55467828924527
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-44
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-44] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435321998
[kafka-producer-network-thread | producer-44] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-44] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-44] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-44] ProducerId set to 938 with epoch 0
[kafka-producer-network-thread | producer-44] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-44] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-44] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-44] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-44] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-44] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-44] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-44 unregistered
Aumentou o pre√ßo do caf√©
Received message: 67.55467828924527
COUNT: 1
Received message: 67.55467828924527
COUNT: 2
Received message: 67.55467828924527
COUNT: 3
Received message: 67.55467828924527
COUNT: 4
Received message: 67.55467828924527
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-45
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-45] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435322763
[kafka-producer-network-thread | producer-45] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-45] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-45] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-45] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-45] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-45] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-45] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-45] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-45] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-45] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-45] ProducerId set to 939 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-45 unregistered
Aumentou o pre√ßo do caf√©
Received message: 67.55467828924527
COUNT: 1
Received message: 45.03645219283018
COUNT: 2
Received message: 53.11232006181197
COUNT: 3
Received message: 53.11232006181197
COUNT: 4
Received message: 53.11232006181197
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-46
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-46] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435323881
[kafka-producer-network-thread | producer-46] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-46] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-46] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-46] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-46] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-46] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-46] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-46] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-46] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-46] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-46] ProducerId set to 942 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-46 unregistered
Aumentou o pre√ßo do caf√©
Received message: 53.11232006181197
COUNT: 1
Received message: 53.11232006181197
COUNT: 2
Received message: 53.11232006181197
COUNT: 3
Received message: 53.11232006181197
COUNT: 4
Received message: 63.48076381681177
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-47
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-47] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435325114
[kafka-producer-network-thread | producer-47] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-47] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-47] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-47] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-47] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-47] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-47] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-47] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-47] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-47] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-47] ProducerId set to 946 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-47 unregistered
Aumentou o pre√ßo do caf√©
Received message: 63.48076381681177
COUNT: 1
Received message: 63.48076381681177
COUNT: 2
Received message: 63.48076381681177
COUNT: 3
Received message: 63.48076381681177
COUNT: 4
Received message: 63.48076381681177
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-48
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-48] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435326023
[kafka-producer-network-thread | producer-48] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-48] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-48] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-48] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-48] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-48] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-48] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-48] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-48] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-48] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-48] ProducerId set to 947 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-48 unregistered
Aumentou o pre√ßo do caf√©
Received message: 63.48076381681177
COUNT: 1
Received message: 63.48076381681177
COUNT: 2
Received message: 63.48076381681177
COUNT: 3
Received message: 75.14526304118655
COUNT: 4
Received message: 75.14526304118655
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-49
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-49] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435327035
[kafka-producer-network-thread | producer-49] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-49] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-49] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-49] ProducerId set to 950 with epoch 0
[kafka-producer-network-thread | producer-49] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-49] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-49] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-49] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-49] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-49] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-49] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-49 unregistered
Aumentou o pre√ßo do caf√©
Received message: 75.14526304118655
COUNT: 1
Received message: 75.14526304118655
COUNT: 2
Received message: 88.19341121293095
COUNT: 3
Received message: 88.19341121293095
COUNT: 4
Received message: 88.19341121293095
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-50
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-50] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435331169
[kafka-producer-network-thread | producer-50] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-50] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-50] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-50] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-50] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-50] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-50] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-50] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-50] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-50] ProducerId set to 955 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-50] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-50 unregistered
Aumentou o pre√ßo do caf√©
Received message: 88.19341121293095
COUNT: 1
Received message: 102.87257790614339
COUNT: 2
Received message: 102.87257790614339
COUNT: 3
Received message: 102.87257790614339
COUNT: 4
Received message: 102.87257790614339
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-51
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-51] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435331973
[kafka-producer-network-thread | producer-51] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-51] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-51] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-51] ProducerId set to 958 with epoch 0
[kafka-producer-network-thread | producer-51] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-51] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-51] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-51] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-51] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-51] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-51] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-51 unregistered
Aumentou o pre√ßo do caf√©
Received message: 102.87257790614339
COUNT: 1
Received message: 119.49900782043173
COUNT: 2
Received message: 119.49900782043173
COUNT: 3
Received message: 119.49900782043173
COUNT: 4
Received message: 119.49900782043173
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-52
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-52] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435332967
[kafka-producer-network-thread | producer-52] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-52] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-52] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-52] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-52] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-52] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-52] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-52] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-52] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka-producer-network-thread | producer-52] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-52] ProducerId set to 961 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-52 unregistered
Aumentou o pre√ßo do caf√©
Received message: 119.49900782043173
COUNT: 1
Received message: 138.26679810865238
COUNT: 2
Received message: 138.26679810865238
COUNT: 3
Received message: 138.26679810865238
COUNT: 4
Received message: 138.26679810865238
COUNT: 5
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-53
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-53] Instantiated an idempotent producer.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 3.4.0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 2e1947d240607d53
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1683435336094
[kafka-producer-network-thread | producer-53] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-53] Resetting the last seen epoch of partition coffee_price-0 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-53] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-53] Resetting the last seen epoch of partition coffee_price-2 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-53] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-53] Resetting the last seen epoch of partition coffee_price-1 to 0 since the associated topicId changed from null to wQ29V4z8TyaKiIvwUKynsA
[kafka-producer-network-thread | producer-53] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-53] Cluster ID: RGEnfEBbR2OldctqWI3drA
[kafka-producer-network-thread | producer-53] INFO org.apache.kafka.clients.producer.internals.TransactionManager - [Producer clientId=producer-53] ProducerId set to 965 with epoch 0
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-53] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Closing reporter org.apache.kafka.common.metrics.JmxReporter
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.metrics.Metrics - Metrics reporters closed
[kafka.InterfaceConsumer.main()] INFO org.apache.kafka.common.utils.AppInfoParser - App info kafka.producer for producer-53 unregistered
Aumentou o pre√ßo do caf√©
